{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4590c2d3-dacc-4f04-95e8-eb2c56d07665",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab87724d-c9b7-42e5-8291-f3396ec37363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca20fb7-36e6-44d5-b735-fea458811568",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c58b57-4dcf-42b0-9e81-8367ffef6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motion Datasets\n",
    "m_left_datas_1, m_left_datas_2, m_left_datas_3 = scipy.io.loadmat('dataset/mat/left_1_2-4.mat'), scipy.io.loadmat('dataset/mat/left_2_2-4.mat'), scipy.io.loadmat('dataset/mat/left_3_2-4.mat')\n",
    "m_right_datas_1, m_right_datas_2, m_right_datas_3 = scipy.io.loadmat('dataset/mat/right_1_2-4.mat'), scipy.io.loadmat('dataset/mat/right_2_2-4.mat'), scipy.io.loadmat('dataset/mat/right_3_2-4.mat')\n",
    "\n",
    "# Duration Datasets\n",
    "d_left_datas_1, d_left_datas_2, d_left_datas_3 = scipy.io.loadmat('dataset/mat/left_1_1.5-3.mat'), scipy.io.loadmat('dataset/mat/left_2_1.5-3.mat'), scipy.io.loadmat('dataset/mat/left_3_1.5-3.mat')\n",
    "d_right_datas_1, d_right_datas_2, d_right_datas_3 = scipy.io.loadmat('dataset/mat/right_1_1.5-3.mat'), scipy.io.loadmat('dataset/mat/right_2_1.5-3.mat'), scipy.io.loadmat('dataset/mat/right_3_1.5-3.mat')\n",
    "\n",
    "# Preparation Datasets\n",
    "p_left_datas_1, p_left_datas_2, p_left_datas_3 = scipy.io.loadmat('dataset/mat/left_1_1-2.mat'), scipy.io.loadmat('dataset/mat/left_2_1-2.mat'), scipy.io.loadmat('dataset/mat/left_3_1-2.mat')\n",
    "p_right_datas_1, p_right_datas_2, p_right_datas_3 = scipy.io.loadmat('dataset/mat/right_1_1-2.mat'), scipy.io.loadmat('dataset/mat/right_2_1-2.mat'), scipy.io.loadmat('dataset/mat/right_3_1-2.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7f6668b-ab78-4e09-bbeb-cbd8f6c5829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motion with all channels\n",
    "m_all_left_datas = np.delete(np.concatenate((m_left_datas_1['left'], m_left_datas_2['left'], m_left_datas_3['left']), axis = 2), 31, 0)\n",
    "m_all_right_datas = np.delete(np.concatenate((m_right_datas_1['right'], m_right_datas_2['right'], m_right_datas_3['right']), axis = 2), 31, 0)\n",
    "\n",
    "# Duration with all channels\n",
    "d_all_left_datas = np.delete(np.concatenate((d_left_datas_1['left'], d_left_datas_2['left'], d_left_datas_3['left']), axis = 2), 31, 0)\n",
    "d_all_right_datas = np.delete(np.concatenate((d_right_datas_1['right'], d_right_datas_2['right'], d_right_datas_3['right']), axis = 2), 31, 0)\n",
    "\n",
    "# Preparation with all channels\n",
    "p_all_left_datas = np.delete(np.concatenate((p_left_datas_1['left'], p_left_datas_2['left'], p_left_datas_3['left']), axis = 2), 31, 0)\n",
    "p_all_right_datas = np.delete(np.concatenate((p_right_datas_1['right'], p_right_datas_2['right'], p_right_datas_3['right']), axis = 2), 31, 0)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------------- #\n",
    "remove_channels = [i for i in range(32) if i != 7 and i != 23 and i != 24]\n",
    "\n",
    "# Motion with only C3, C4, Cz channels\n",
    "m_remove_left_datas = np.delete(np.concatenate((m_left_datas_1['left'], m_left_datas_2['left'], m_left_datas_3['left']), axis = 2), remove_channels, 0)\n",
    "m_remove_right_datas = np.delete(np.concatenate((m_right_datas_1['right'], m_right_datas_2['right'], m_right_datas_3['right']), axis = 2), remove_channels, 0)\n",
    "\n",
    "# Duration with only C3, C4, Cz channels\n",
    "d_remove_left_datas = np.delete(np.concatenate((d_left_datas_1['left'], d_left_datas_2['left'], d_left_datas_3['left']), axis = 2), remove_channels, 0)\n",
    "d_remove_right_datas = np.delete(np.concatenate((d_right_datas_1['right'], d_right_datas_2['right'], d_right_datas_3['right']), axis = 2), remove_channels, 0)\n",
    "\n",
    "# Preparation with only C3, C4, Cz channels\n",
    "p_remove_left_datas = np.delete(np.concatenate((p_left_datas_1['left'], p_left_datas_2['left'], p_left_datas_3['left']), axis = 2), remove_channels, 0)\n",
    "p_remove_right_datas = np.delete(np.concatenate((p_right_datas_1['right'], p_right_datas_2['right'], p_right_datas_3['right']), axis = 2), remove_channels, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50e0c607-2dcd-4fb0-a04b-bd7644aa9322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 1, 31, 1000) (400, 1, 3, 1000) (400, 1, 31, 750) (400, 1, 3, 750) (400, 1, 31, 500) (400, 1, 3, 500)\n"
     ]
    }
   ],
   "source": [
    "# Motion with all channels\n",
    "m_all_datas = np.concatenate((m_all_left_datas, m_all_right_datas), axis = 2)\n",
    "m_all_datas = np.transpose(np.expand_dims(m_all_datas, axis = 1), (3, 1, 0, 2))\n",
    "\n",
    "# Duration with all channels\n",
    "d_all_datas = np.concatenate((d_all_left_datas, d_all_right_datas), axis = 2)\n",
    "d_all_datas = np.transpose(np.expand_dims(d_all_datas, axis = 1), (3, 1, 0, 2))\n",
    "\n",
    "# Preparation with all channels\n",
    "p_all_datas = np.concatenate((p_all_left_datas, p_all_right_datas), axis = 2)\n",
    "p_all_datas = np.transpose(np.expand_dims(p_all_datas, axis = 1), (3, 1, 0, 2))\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------ #\n",
    "\n",
    "# Motion with only C3, C4, Cz channels\n",
    "m_remove_datas = np.concatenate((m_remove_left_datas, m_remove_right_datas), axis = 2)\n",
    "m_remove_datas = np.transpose(np.expand_dims(m_remove_datas, axis = 1), (3, 1, 0, 2))\n",
    "\n",
    "# Duration with only C3, C4, Cz channels\n",
    "d_remove_datas = np.concatenate((d_remove_left_datas, d_remove_right_datas), axis = 2)\n",
    "d_remove_datas = np.transpose(np.expand_dims(d_remove_datas, axis = 1), (3, 1, 0, 2))\n",
    "\n",
    "# Preparation with only C3, C4, Cz channels\n",
    "p_remove_datas = np.concatenate((p_remove_left_datas, p_remove_right_datas), axis = 2)\n",
    "p_remove_datas = np.transpose(np.expand_dims(p_remove_datas, axis = 1), (3, 1, 0, 2))\n",
    "\n",
    "labels = np.array([0 for i in range(200)] + [1 for i in range(200)])\n",
    "\n",
    "print(m_all_datas.shape, m_remove_datas.shape, d_all_datas.shape, d_remove_datas.shape, p_all_datas.shape, p_remove_datas.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28edc790-9530-4a13-b868-42cb89447371",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5896a5-739d-40b1-8bed-13dfae806f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, epoches = 10, 300\n",
    "\n",
    "# Motion with all channels\n",
    "m_all_train_datas, m_all_test_datas, m_all_train_labels, m_all_test_labels = train_test_split(m_all_datas, labels, shuffle = True, test_size = 0.2, random_state = 23)\n",
    "\n",
    "m_all_train_datas, m_all_train_labels = torch.from_numpy(m_all_train_datas), torch.from_numpy(m_all_train_labels)\n",
    "m_all_test_datas, m_all_test_labels = torch.from_numpy(m_all_test_datas), torch.from_numpy(m_all_test_labels)\n",
    "\n",
    "m_all_train_loader = DataLoader(TensorDataset(m_all_train_datas, m_all_train_labels), batch_size = batch_size, shuffle = True)\n",
    "m_all_test_loader = DataLoader(TensorDataset(m_all_test_datas, m_all_test_labels), batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# Duration with all channels\n",
    "d_all_train_datas, d_all_test_datas, d_all_train_labels, d_all_test_labels = train_test_split(d_all_datas, labels, shuffle = True, test_size = 0.2, random_state = 23)\n",
    "\n",
    "d_all_train_datas, d_all_train_labels = torch.from_numpy(d_all_train_datas), torch.from_numpy(d_all_train_labels)\n",
    "d_all_test_datas, d_all_test_labels = torch.from_numpy(d_all_test_datas), torch.from_numpy(d_all_test_labels)\n",
    "\n",
    "d_all_train_loader = DataLoader(TensorDataset(d_all_train_datas, d_all_train_labels), batch_size = batch_size, shuffle = True)\n",
    "d_all_test_loader = DataLoader(TensorDataset(d_all_test_datas, d_all_test_labels), batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# Preparation with all channels\n",
    "p_all_train_datas, p_all_test_datas, p_all_train_labels, p_all_test_labels = train_test_split(p_all_datas, labels, shuffle = True, test_size = 0.2, random_state = 23)\n",
    "\n",
    "p_all_train_datas, p_all_train_labels = torch.from_numpy(p_all_train_datas), torch.from_numpy(p_all_train_labels)\n",
    "p_all_test_datas, p_all_test_labels = torch.from_numpy(p_all_test_datas), torch.from_numpy(p_all_test_labels)\n",
    "\n",
    "p_all_train_loader = DataLoader(TensorDataset(p_all_train_datas, p_all_train_labels), batch_size = batch_size, shuffle = True)\n",
    "p_all_test_loader = DataLoader(TensorDataset(p_all_test_datas, p_all_test_labels), batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ #\n",
    "\n",
    "# Motion with only C3, C4, Cz channels\n",
    "m_remove_train_datas, m_remove_test_datas, m_remove_train_labels, m_remove_test_labels = train_test_split(m_remove_datas, labels, shuffle = True, test_size = 0.2, random_state = 23)\n",
    "\n",
    "m_remove_train_datas, m_remove_train_labels = torch.from_numpy(m_remove_train_datas), torch.from_numpy(m_remove_train_labels)\n",
    "m_remove_test_datas, m_remove_test_labels = torch.from_numpy(m_remove_test_datas), torch.from_numpy(m_remove_test_labels)\n",
    "\n",
    "m_remove_train_loader = DataLoader(TensorDataset(m_remove_train_datas, m_remove_train_labels), batch_size = batch_size, shuffle = True)\n",
    "m_remove_test_loader = DataLoader(TensorDataset(m_remove_test_datas, m_remove_test_labels), batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# Duration with only C3, C4, Cz channels\n",
    "d_remove_train_datas, d_remove_test_datas, d_remove_train_labels, d_remove_test_labels = train_test_split(d_remove_datas, labels, shuffle = True, test_size = 0.2, random_state = 23)\n",
    "\n",
    "d_remove_train_datas, d_remove_train_labels = torch.from_numpy(d_remove_train_datas), torch.from_numpy(d_remove_train_labels)\n",
    "d_remove_test_datas, d_remove_test_labels = torch.from_numpy(d_remove_test_datas), torch.from_numpy(d_remove_test_labels)\n",
    "\n",
    "d_remove_train_loader = DataLoader(TensorDataset(d_remove_train_datas, d_remove_train_labels), batch_size = batch_size, shuffle = True)\n",
    "d_remove_test_loader = DataLoader(TensorDataset(d_remove_test_datas, d_remove_test_labels), batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# Preparation with only C3, C4, Cz channels\n",
    "p_remove_train_datas, p_remove_test_datas, p_remove_train_labels, p_remove_test_labels = train_test_split(p_remove_datas, labels, shuffle = True, test_size = 0.2, random_state = 23)\n",
    "\n",
    "p_remove_train_datas, p_remove_train_labels = torch.from_numpy(p_remove_train_datas), torch.from_numpy(p_remove_train_labels)\n",
    "p_remove_test_datas, p_remove_test_labels = torch.from_numpy(p_remove_test_datas), torch.from_numpy(p_remove_test_labels)\n",
    "\n",
    "p_remove_train_loader = DataLoader(TensorDataset(p_remove_train_datas, p_remove_train_labels), batch_size = batch_size, shuffle = True)\n",
    "p_remove_test_loader = DataLoader(TensorDataset(p_remove_test_datas, p_remove_test_labels), batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e516f50b-5240-4f2a-ae87-34ac7516b122",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# EEGNet and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "895ee092-0dda-4cac-878d-2a26d43be637",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(torch.nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(EEGNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size = (1, 51), stride = (1, 1), padding = (0, 25), bias = False)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, eps = 1e-5, momentum = 0.1, affine = True, track_running_stats = True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size = (2, 1), stride = (1, 1), groups = 16, bias = False)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32, eps = 1e-5, momentum = 0.1, affine = True, track_running_stats = True)\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size = (1, 4), stride = (1, 4), padding = 0)\n",
    "        self.dropout2 = nn.Dropout(p = 0.25)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size = (1, 15), stride = (1, 1), padding = (0, 7), bias = False)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(32, eps = 1e-5, momentum = 0.1, affine = True, track_running_stats = True)\n",
    "        self.avgpool3 = nn.AvgPool2d(kernel_size = (1, 8), stride = (1, 8), padding = 0)\n",
    "        self.dropout3 = nn.Dropout(p = 0.25)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features = in_features, out_features = 2, bias = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batchnorm1(self.conv1(x))\n",
    "        \n",
    "        x = F.relu(self.batchnorm2(self.conv2(x)))\n",
    "        x = self.dropout2(self.avgpool2(x))\n",
    "        \n",
    "        x = F.relu(self.batchnorm3(self.conv3(x)))\n",
    "        x = self.dropout3(self.avgpool3(x))\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "233e72d0-5711-471c-840a-bfe878634556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_string(epoch, epoches, start_time, train_correct, train_total, test_correct, test_total):\n",
    "    log_string = f'[{epoch + 1:03d}/{epoches:03d}] {time.time() - start_time:2.2f}sec | Train: {train_correct / train_total * 100:3.2f}% | Test: {test_correct / test_total * 100:3.2f}%'\n",
    "    return log_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb010bb6-2c9b-423b-a471-f72865a11ac0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea993b66-9a93-4e99-a79b-82a472ebb875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd587ec3eb20448e99ce1c6300d307f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |0/40[?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Motion with all channels\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "m_all_model = EEGNet(in_features = 29760).to(device)\n",
    "\n",
    "learning_rate = 2e-6\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(m_all_model.parameters(), lr = learning_rate)\n",
    "\n",
    "best_accuracy = 0.0\n",
    "progress = tqdm(\n",
    "    total = len(m_all_train_loader) + len(m_all_test_loader), \n",
    "    colour = 'purple', \n",
    "    bar_format = '{desc}{percentage:3.0f}%|{bar}|{n}/{total}[{rate_fmt}{postfix}]'\n",
    ")\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    start_time = time.time()\n",
    "    train_correct, test_correct, train_total, test_total = 0.0, 0.0, 1e-3, 1e-3\n",
    "    \n",
    "    m_all_model.train()\n",
    "    \n",
    "    for x_batch, y_batch in m_all_train_loader:        \n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        y_prediction = m_all_model.forward(x_batch.float())\n",
    "        loss = criterion(y_prediction, y_batch.type(torch.LongTensor).to(device)) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        prediction = y_prediction.data.max(1, keepdim = True)[1]\n",
    "        train_correct += np.sum(np.squeeze(prediction.eq(y_batch.data.view_as(prediction))).cpu().numpy())\n",
    "        train_total += x_batch.size(0)\n",
    "        \n",
    "        progress.set_description(\n",
    "            get_log_string(epoch, epoches, start_time, train_correct, train_total, test_correct, test_total)\n",
    "        )\n",
    "        progress.update(1)\n",
    "\n",
    "    m_all_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in m_all_test_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            y_prediction = m_all_model.forward(x_batch.float())\n",
    "            loss = criterion(y_prediction, y_batch.type(torch.LongTensor).to(device))\n",
    "            \n",
    "            prediction = y_prediction.data.max(1, keepdim = True)[1]\n",
    "            test_correct += np.sum(np.squeeze(prediction.eq(y_batch.data.view_as(prediction))).cpu().numpy())\n",
    "            test_total += x_batch.size(0)\n",
    "            \n",
    "            progress.set_description(\n",
    "                get_log_string(epoch, epoches, start_time, train_correct, train_total, test_correct, test_total)\n",
    "            )\n",
    "            progress.update(1)\n",
    "\n",
    "    if (test_correct / test_total * 100) > best_accuracy:\n",
    "        best_accuracy = test_correct / test_total * 100\n",
    "        torch.save(m_all_model.state_dict(), 'model/m_all_model.pth')\n",
    "    \n",
    "    if epoch != epoches - 1: progress.reset()\n",
    "\n",
    "try:\n",
    "    os.rename('model/m_all_model.pth', f'model/m_all_model_{best_accuracy:.2f}.pth')\n",
    "except FileExistsError:\n",
    "    os.remove('model/m_all_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46095057-6fba-478d-9564-20cc10e86d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec87bfdd95be45a79ea65a64cdc9c380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |0/40[?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Duration with all channels\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "d_all_model = EEGNet(in_features = 22080).to(device)\n",
    "\n",
    "learning_rate = 2e-6\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(d_all_model.parameters(), lr = learning_rate)\n",
    "\n",
    "best_accuracy = 0.0\n",
    "progress = tqdm(\n",
    "    total = len(d_all_train_loader) + len(d_all_test_loader), \n",
    "    colour = 'purple', \n",
    "    bar_format = '{desc}{percentage:3.0f}%|{bar}|{n}/{total}[{rate_fmt}{postfix}]'\n",
    ")\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    start_time = time.time()\n",
    "    train_correct, test_correct, train_total, test_total = 0.0, 0.0, 1e-3, 1e-3\n",
    "    \n",
    "    d_all_model.train()\n",
    "    \n",
    "    for x_batch, y_batch in d_all_train_loader:        \n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        y_prediction = d_all_model.forward(x_batch.float())\n",
    "        loss = criterion(y_prediction, y_batch.type(torch.LongTensor).to(device)) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        prediction = y_prediction.data.max(1, keepdim = True)[1]\n",
    "        train_correct += np.sum(np.squeeze(prediction.eq(y_batch.data.view_as(prediction))).cpu().numpy())\n",
    "        train_total += x_batch.size(0)\n",
    "        \n",
    "        progress.set_description(\n",
    "            get_log_string(epoch, epoches, start_time, train_correct, train_total, test_correct, test_total)\n",
    "        )\n",
    "        progress.update(1)\n",
    "\n",
    "    d_all_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in d_all_test_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            y_prediction = d_all_model.forward(x_batch.float())\n",
    "            loss = criterion(y_prediction, y_batch.type(torch.LongTensor).to(device))\n",
    "            \n",
    "            prediction = y_prediction.data.max(1, keepdim = True)[1]\n",
    "            test_correct += np.sum(np.squeeze(prediction.eq(y_batch.data.view_as(prediction))).cpu().numpy())\n",
    "            test_total += x_batch.size(0)\n",
    "            \n",
    "            progress.set_description(\n",
    "                get_log_string(epoch, epoches, start_time, train_correct, train_total, test_correct, test_total)\n",
    "            )\n",
    "            progress.update(1)\n",
    "\n",
    "    if (test_correct / test_total * 100) > best_accuracy:\n",
    "        best_accuracy = test_correct / test_total * 100\n",
    "        torch.save(d_all_model.state_dict(), 'model/d_all_model.pth')\n",
    "    \n",
    "    if epoch != epoches - 1: progress.reset()\n",
    "\n",
    "try:\n",
    "    os.rename('model/d_all_model.pth', f'model/d_all_model_{best_accuracy:.2f}.pth')\n",
    "except FileExistsError:\n",
    "    os.remove('model/d_all_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23badfa-b868-4c75-83b9-730e64ce7b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43cf5e6bd1764840b5b3d45cf0702882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |0/40[?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preparation with all channels\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "p_all_model = EEGNet(in_features = 14400).to(device)\n",
    "\n",
    "learning_rate = 2e-6\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(p_all_model.parameters(), lr = learning_rate)\n",
    "\n",
    "best_accuracy = 0.0\n",
    "progress = tqdm(\n",
    "    total = len(p_all_train_loader) + len(p_all_test_loader), \n",
    "    colour = 'purple', \n",
    "    bar_format = '{desc}{percentage:3.0f}%|{bar}|{n}/{total}[{rate_fmt}{postfix}]'\n",
    ")\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    start_time = time.time()\n",
    "    train_correct, test_correct, train_total, test_total = 0.0, 0.0, 1e-3, 1e-3\n",
    "    \n",
    "    p_all_model.train()\n",
    "    \n",
    "    for x_batch, y_batch in p_all_train_loader:        \n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        y_prediction = p_all_model.forward(x_batch.float())\n",
    "        loss = criterion(y_prediction, y_batch.type(torch.LongTensor).to(device)) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        prediction = y_prediction.data.max(1, keepdim = True)[1]\n",
    "        train_correct += np.sum(np.squeeze(prediction.eq(y_batch.data.view_as(prediction))).cpu().numpy())\n",
    "        train_total += x_batch.size(0)\n",
    "        \n",
    "        progress.set_description(\n",
    "            get_log_string(epoch, epoches, start_time, train_correct, train_total, test_correct, test_total)\n",
    "        )\n",
    "        progress.update(1)\n",
    "\n",
    "    p_all_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in p_all_test_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            y_prediction = p_all_model.forward(x_batch.float())\n",
    "            loss = criterion(y_prediction, y_batch.type(torch.LongTensor).to(device))\n",
    "            \n",
    "            prediction = y_prediction.data.max(1, keepdim = True)[1]\n",
    "            test_correct += np.sum(np.squeeze(prediction.eq(y_batch.data.view_as(prediction))).cpu().numpy())\n",
    "            test_total += x_batch.size(0)\n",
    "            \n",
    "            progress.set_description(\n",
    "                get_log_string(epoch, epoches, start_time, train_correct, train_total, test_correct, test_total)\n",
    "            )\n",
    "            progress.update(1)\n",
    "\n",
    "    if (test_correct / test_total * 100) > best_accuracy:\n",
    "        best_accuracy = test_correct / test_total * 100\n",
    "        torch.save(p_all_model.state_dict(), 'model/p_all_model.pth')\n",
    "    \n",
    "    if epoch != epoches - 1: progress.reset()\n",
    "\n",
    "try:\n",
    "    os.rename('model/p_all_model.pth', f'model/p_all_model_{best_accuracy:.2f}.pth')\n",
    "except FileExistsError:\n",
    "    os.remove('model/p_all_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de13bacd-1bfc-4a49-b0a8-55844abfcd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c71d9a48ef4153a6672f6c62c20f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |0/40[?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Motion with only C3, C4, Cz channels\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "m_remove_model = EEGNet(in_features = 1984).to(device)\n",
    "\n",
    "learning_rate = 8e-5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(m_remove_model.parameters(), lr = learning_rate)\n",
    "\n",
    "best_accuracy = 0.0\n",
    "progress = tqdm(\n",
    "    total = len(m_remove_train_loader) + len(m_remove_test_loader), \n",
    "    colour = 'purple', \n",
    "    bar_format = '{desc}{percentage:3.0f}%|{bar}|{n}/{total}[{rate_fmt}{postfix}]'\n",
    ")\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    start_time = time.time()\n",
    "    train_correct, test_correct, train_total, test_total = 0.0, 0.0, 1e-3, 1e-3\n",
    "    \n",
    "    m_remove_model.train()\n",
    "    \n",
    "    for x_batch, y_batch in m_remove_train_loader:        \n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        y_prediction = m_remove_model.forward(x_batch.float())\n",
    "        loss = criterion(y_prediction, y_batch.type(torch.LongTensor).to(device)) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        prediction = y_prediction.data.max(1, keepdim = True)[1]\n",
    "        train_correct += np.sum(np.squeeze(prediction.eq(y_batch.data.view_as(prediction))).cpu().numpy())\n",
    "        train_total += x_batch.size(0)\n",
    "        \n",
    "        progress.set_description(\n",
    "            get_log_string(epoch, epoches, start_time, train_correct, train_total, test_correct, test_total)\n",
    "        )\n",
    "        progress.update(1)\n",
    "\n",
    "    m_remove_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in m_remove_test_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            y_prediction = m_remove_model.forward(x_batch.float())\n",
    "            loss = criterion(y_prediction, y_batch.type(torch.LongTensor).to(device))\n",
    "            \n",
    "            prediction = y_prediction.data.max(1, keepdim = True)[1]\n",
    "            test_correct += np.sum(np.squeeze(prediction.eq(y_batch.data.view_as(prediction))).cpu().numpy())\n",
    "            test_total += x_batch.size(0)\n",
    "            \n",
    "            progress.set_description(\n",
    "                get_log_string(epoch, epoches, start_time, train_correct, train_total, test_correct, test_total)\n",
    "            )\n",
    "            progress.update(1)\n",
    "\n",
    "    if (test_correct / test_total * 100) > best_accuracy:\n",
    "        best_accuracy = test_correct / test_total * 100\n",
    "        torch.save(m_remove_model.state_dict(), 'model/m_remove_model.pth')\n",
    "    \n",
    "    if epoch != epoches - 1: progress.reset()\n",
    "\n",
    "try:\n",
    "    os.rename('model/m_remove_model.pth', f'model/m_remove_model_{best_accuracy:.2f}.pth')\n",
    "except FileExistsError:\n",
    "    os.remove('model/m_remove_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42b7868d-d458-4d20-b93e-278ea24e014e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0cc63180734e08980f05de1272bb73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |0/40[?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Duration with only C3, C4, Cz channels\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "d_remove_model = EEGNet(in_features = 1472).to(device)\n",
    "\n",
    "learning_rate = 8e-5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(d_remove_model.parameters(), lr = learning_rate)\n",
    "\n",
    "best_accuracy = 0.0\n",
    "progress = tqdm(\n",
    "    total = len(d_remove_train_loader) + len(d_remove_test_loader), \n",
    "    colour = 'purple', \n",
    "    bar_format = '{desc}{percentage:3.0f}%|{bar}|{n}/{total}[{rate_fmt}{postfix}]'\n",
    ")\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    start_time = time.time()\n",
    "    train_correct, test_correct, train_total, test_total = 0.0, 0.0, 1e-3, 1e-3\n",
    "    \n",
    "    d_remove_model.train()\n",
    "    \n",
    "    for x_batch, y_batch in d_remove_train_loader:        \n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        y_prediction = d_remove_model.forward(x_batch.float())\n",
    "        loss = criterion(y_prediction, y_batch.type(torch.LongTensor).to(device)) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        prediction = y_prediction.data.max(1, keepdim = True)[1]\n",
    "        train_correct += np.sum(np.squeeze(prediction.eq(y_batch.data.view_as(prediction))).cpu().numpy())\n",
    "        train_total += x_batch.size(0)\n",
    "        \n",
    "        progress.set_description(\n",
    "            get_log_string(epoch, epoches, start_time, train_correct, train_total, test_correct, test_total)\n",
    "        )\n",
    "        progress.update(1)\n",
    "\n",
    "    d_remove_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in d_remove_test_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            y_prediction = d_remove_model.forward(x_batch.float())\n",
    "            loss = criterion(y_prediction, y_batch.type(torch.LongTensor).to(device))\n",
    "            \n",
    "            prediction = y_prediction.data.max(1, keepdim = True)[1]\n",
    "            test_correct += np.sum(np.squeeze(prediction.eq(y_batch.data.view_as(prediction))).cpu().numpy())\n",
    "            test_total += x_batch.size(0)\n",
    "            \n",
    "            progress.set_description(\n",
    "                get_log_string(epoch, epoches, start_time, train_correct, train_total, test_correct, test_total)\n",
    "            )\n",
    "            progress.update(1)\n",
    "\n",
    "    if (test_correct / test_total * 100) > best_accuracy:\n",
    "        best_accuracy = test_correct / test_total * 100\n",
    "        torch.save(d_remove_model.state_dict(), 'model/d_remove_model.pth')\n",
    "    \n",
    "    if epoch != epoches - 1: progress.reset()\n",
    "\n",
    "try:\n",
    "    os.rename('model/d_remove_model.pth', f'model/d_remove_model_{best_accuracy:.2f}.pth')\n",
    "except FileExistsError:\n",
    "    os.remove('model/d_remove_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83486b44-63ad-4c5d-81f3-1626894a9d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beceffe91bad4099a1b845d85f171528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |0/40[?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preparation with only C3, C4, Cz channels\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "p_remove_model = EEGNet(in_features = 960).to(device)\n",
    "\n",
    "learning_rate = 8e-5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(p_remove_model.parameters(), lr = learning_rate)\n",
    "\n",
    "best_accuracy = 0.0\n",
    "progress = tqdm(\n",
    "    total = len(p_remove_train_loader) + len(p_remove_test_loader), \n",
    "    colour = 'purple', \n",
    "    bar_format = '{desc}{percentage:3.0f}%|{bar}|{n}/{total}[{rate_fmt}{postfix}]'\n",
    ")\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    start_time = time.time()\n",
    "    train_correct, test_correct, train_total, test_total = 0.0, 0.0, 1e-3, 1e-3\n",
    "    \n",
    "    p_remove_model.train()\n",
    "    \n",
    "    for x_batch, y_batch in p_remove_train_loader:        \n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        y_prediction = p_remove_model.forward(x_batch.float())\n",
    "        loss = criterion(y_prediction, y_batch.type(torch.LongTensor).to(device)) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        prediction = y_prediction.data.max(1, keepdim = True)[1]\n",
    "        train_correct += np.sum(np.squeeze(prediction.eq(y_batch.data.view_as(prediction))).cpu().numpy())\n",
    "        train_total += x_batch.size(0)\n",
    "        \n",
    "        progress.set_description(\n",
    "            get_log_string(epoch, epoches, start_time, train_correct, train_total, test_correct, test_total)\n",
    "        )\n",
    "        progress.update(1)\n",
    "\n",
    "    p_remove_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in p_remove_test_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            y_prediction = p_remove_model.forward(x_batch.float())\n",
    "            loss = criterion(y_prediction, y_batch.type(torch.LongTensor).to(device))\n",
    "            \n",
    "            prediction = y_prediction.data.max(1, keepdim = True)[1]\n",
    "            test_correct += np.sum(np.squeeze(prediction.eq(y_batch.data.view_as(prediction))).cpu().numpy())\n",
    "            test_total += x_batch.size(0)\n",
    "            \n",
    "            progress.set_description(\n",
    "                get_log_string(epoch, epoches, start_time, train_correct, train_total, test_correct, test_total)\n",
    "            )\n",
    "            progress.update(1)\n",
    "\n",
    "    if (test_correct / test_total * 100) > best_accuracy:\n",
    "        best_accuracy = test_correct / test_total * 100\n",
    "        torch.save(p_remove_model.state_dict(), 'model/p_remove_model.pth')\n",
    "    \n",
    "    if epoch != epoches - 1: progress.reset()\n",
    "\n",
    "try:\n",
    "    os.rename('model/p_remove_model.pth', f'model/p_remove_model_{best_accuracy:.2f}.pth')\n",
    "except FileExistsError:\n",
    "    os.remove('model/p_remove_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf145f0-b3ff-455b-8a6d-b5ee94471606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
